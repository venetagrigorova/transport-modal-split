{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Pocketbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read the spreadsheets into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General data\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '../data/StatisticalPocketbook/pb2023-section1.xlsx'\n",
    "\n",
    "# Specify the sheet names\n",
    "sheet_names = ['general', 'growth', 'empl_rate', 'unempl_rate', 'share_gross_value_added', 'share_empl', 'population', 'trade_import', 'trade_export', 'EU-world']\n",
    "\n",
    "# Read the specified sheets into a dictionary of DataFrames\n",
    "general_dfs = pd.read_excel(file_path, sheet_name=sheet_names, header=0, index_col=0)\n",
    "\n",
    "# Results\n",
    "for name, df in general_dfs.items():\n",
    "    print(f\"DataFrame for sheet {name}:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the relevant data from \"General\" into 1 dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add population density\n",
    "general_dfs['general']['PopDensity'] = general_dfs['general']['Population'] / general_dfs['general']['Area']\n",
    "\n",
    "# Keep only last year entries (most current) for \"growth\"(industrial production growth); employment and unemployment rate\n",
    "general_dfs['growth'] = general_dfs['growth'].iloc[:, [-1]]\n",
    "general_dfs['growth'].columns = ['indust_growth']\n",
    "general_dfs['empl_rate'] = general_dfs['empl_rate'].iloc[:, [-1]]\n",
    "general_dfs['empl_rate'].columns = ['empl_rate']\n",
    "\n",
    "general_dfs['share_gross_value_added'].columns = ['GVA_agriculture', 'GVA_industry', 'GVA_services']\n",
    "general_dfs['share_empl'].columns = ['emplshare_agriculture', 'emplshare_industry', 'emplshare_services']\n",
    "\n",
    "general_dfs['trade_import'] = general_dfs['trade_import'].iloc[:, [0]]\n",
    "general_dfs['trade_import'].columns = ['trade_import_w']\n",
    "general_dfs['trade_export'] = general_dfs['trade_export'].iloc[:, [0]]\n",
    "general_dfs['trade_export'].columns = ['trade_export_w']\n",
    "\n",
    "# Concatenate the DataFrames by row index\n",
    "chosen_dfs = [general_dfs['general'], general_dfs['growth'], general_dfs['empl_rate'], \n",
    "                        general_dfs['share_gross_value_added'], general_dfs['share_empl'], \n",
    "                        general_dfs['trade_import'], general_dfs['trade_export']]\n",
    "\n",
    "# Compile everything into 1 dataframe\n",
    "general_all = pd.concat(chosen_dfs, axis=1, ignore_index=False)\n",
    "general_all = general_all.drop(\"EU-27\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each column\n",
    "general_all.hist(bins=15, figsize=(12, 8))  \n",
    "plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "plt.show()\n",
    "\n",
    "# Almost all distributions are skewed, investigating ther log-transformations\n",
    "general_all_log = general_all.apply(lambda x: np.log(x) if np.issubdtype(x.dtype, np.number) else x)\n",
    "general_all_log.hist(bins=15, figsize=(12, 8))  \n",
    "plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is definitely beneficial to use log-transformations of all variables (except maybe empl_rate and emplshare_services) when including them in future models, that rely on normally distributed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the general \"Transport\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transport\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '../data/StatisticalPocketbook/pb2023_section21.xlsx'\n",
    "\n",
    "# Specify the sheet names\n",
    "sheet_names = ['limits', 'empl', 'entrpr', 'house_exp_type', 'price_index', 'tax_fuel', 'tax_otrans']\n",
    "\n",
    "# Read the specified sheets into a dictionary of DataFrames\n",
    "transport_dfs = pd.read_excel(file_path, sheet_name=sheet_names, header=0, index_col=0)\n",
    "\n",
    "# Results\n",
    "for name, df in transport_dfs.items():\n",
    "    print(f\"DataFrame for sheet {name}:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the variables and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMITS - some entries have multiple values devided by /. We can take the mean from them.\n",
    "# Define a function for the transformation of entries multiple limits to their mean\n",
    "def mean_column(column):\n",
    "\n",
    "    # Split values by '/' and convert to integers\n",
    "    temp = column.apply(lambda x: [float(val) for val in str(x).split('/')])\n",
    "    # Calculate mean for rows with multiple values\n",
    "    temp = temp.apply(lambda x: np.mean(x) if len(x) > 1 else x[0])\n",
    "    # Convert the column to a numeric data type\n",
    "    temp = pd.to_numeric(temp, errors='coerce')\n",
    "    return temp\n",
    "\n",
    "# Apply the transformation to the specified columns\n",
    "columns_to_transform = ['speed_l_cars_builtup_areas',\n",
    "                        'speed_l_cars_outside_builtup_areas',\n",
    "                        'speed_l_cars_motorways']\n",
    "\n",
    "for column_name in columns_to_transform:\n",
    "    transport_dfs['limits'][column_name] = mean_column(transport_dfs['limits'][column_name])\n",
    "\n",
    "# Number of public transport enterprizes\n",
    "transport_dfs['entrpr'] = transport_dfs['entrpr'].iloc[:, [2]]\n",
    "transport_dfs['entrpr'].columns = ['pass_transport_enterpr']\n",
    "\n",
    "# Transport expenses per head\n",
    "transport_dfs['house_exp_type'] = transport_dfs['house_exp_type'].iloc[:, [-1]]\n",
    "transport_dfs['house_exp_type'].columns = ['expenditure_per_head']\n",
    "\n",
    "# Fuel taxes (as a % of GDP)\n",
    "transport_dfs['tax_fuel'] = transport_dfs['tax_fuel'].iloc[:, [-3]]\n",
    "transport_dfs['tax_fuel'].columns = ['tax_fuel']\n",
    "\n",
    "# other Transport taxes (excl. fuel taxes)\n",
    "transport_dfs['tax_otrans'] = transport_dfs['tax_otrans'].iloc[:, [-3]]\n",
    "transport_dfs['tax_otrans'].columns = ['tax_otrans']\n",
    "\n",
    "# Concatenate the DataFrames by row index\n",
    "chosen_dfs = [transport_dfs['limits'], transport_dfs['entrpr'], transport_dfs['house_exp_type'], \n",
    "                        transport_dfs['tax_fuel'], transport_dfs['tax_otrans']]\n",
    "\n",
    "# Compile everything into 1 dataframe\n",
    "transport_all = pd.concat(chosen_dfs, axis=1, ignore_index=False)\n",
    "transport_all = transport_all.drop(\"EU-27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each column\n",
    "transport_all.hist(bins=15, figsize=(12, 8))  \n",
    "plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of variables here have a distribution where 1 value is dominant due to EU-wide standards (like speed limits and blood alcohol levels). Tests/models that are not dependent on the normal distribution maybe should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance of Passenger Transport\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '../data/StatisticalPocketbook/pb2023_section23.xlsx'\n",
    "\n",
    "# Specify the sheet names\n",
    "sheet_names = ['perf_mode_pkm', 'perf_mode_split', 'split_mode_proz', 'split_mode_pkm', 'cars', 'bus_coach', 'tram_and_metro', 'rail_pkm', 'hs_rail']\n",
    "\n",
    "# Read the specified sheets into a dictionary of DataFrames\n",
    "passenger_dfs = pd.read_excel(file_path, sheet_name=sheet_names, header=0, index_col=0)\n",
    "\n",
    "# Remove rows containing only NaN-s\n",
    "for name, df in passenger_dfs.items():\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    print(f\"DataFrame for sheet {name}:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the \"Performance of Passenger Transport\" we have mainly the modal split by different factors expressed in pkm or in %."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, out of this data we create a data frame modal_split, which includes data in million passenger-kilometers, that will be our main variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_split = passenger_dfs['split_mode_pkm']\n",
    "# Drop \"Total\" column for now\n",
    "modal_split.drop(modal_split.columns[-1], axis=1, inplace=True)\n",
    "# Remove countries without data\n",
    "modal_split = modal_split.dropna(how='all')\n",
    "# Replace all other NaN-s with 0\n",
    "modal_split = modal_split.fillna(0)\n",
    "# Rename columns\n",
    "modal_split.columns = ['cars', 'bus_coach', 'railways', 'tram_metro']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating modal_split_proz (a data frame for modal split in percentage) separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modal_split_proz = passenger_dfs['split_mode_proz']\n",
    "modal_split_proz.set_index('Unnamed: 1', inplace=True)\n",
    "# Remove countries without data\n",
    "modal_split_proz = modal_split_proz.dropna(how='all')\n",
    "# Replace all other NaN-s with 0\n",
    "modal_split_proz = modal_split_proz.fillna(0)\n",
    "# Rename columns\n",
    "modal_split_proz.columns = ['cars', 'bus_coach', 'railways', 'tram_metro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the modal split as a bar chart\n",
    "modal_split_proz.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Modal Split of Passenger Transport by Country and Means of Transport (2021)')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort the DataFrame by the 'tram_metro' column in descending order\n",
    "modal_split_sorted = modal_split_proz.sort_values(by='tram_metro', ascending=False)\n",
    "\n",
    "# Plot the modal split as a bar chart\n",
    "modal_split_sorted.plot(kind='bar', stacked=True, figsize=(12, 8))\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Percentage (%)')\n",
    "plt.title('Modal Split of Passenger Transport by Country and Means of Transport (2021) - Ordered by Tram & Metro')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infrastructure\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '../data/StatisticalPocketbook/pb2023_section25.xlsx'\n",
    "\n",
    "# Specify the sheet names\n",
    "sheet_names = ['motorway', 'length_road', 'rail_length', 'airports', 'ports', 'length_oil']\n",
    "\n",
    "# Read the specified sheets into a dictionary of DataFrames\n",
    "infrastructure_dfs = pd.read_excel(file_path, sheet_name=sheet_names, header=4, index_col=1)\n",
    "\n",
    "# Results\n",
    "for name, df in infrastructure_dfs.items():\n",
    "    print(f\"DataFrame for sheet {name}:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infrastructure_dfs['motorway'] = infrastructure_dfs['motorway'].iloc[:, [-1]]\n",
    "infrastructure_dfs['motorway'].columns = ['len_motorway']\n",
    "\n",
    "infrastructure_dfs['length_road']['len_total_road'] = infrastructure_dfs['length_road'].sum(axis=1, skipna=True)\n",
    "infrastructure_dfs['length_road'] = infrastructure_dfs['length_road'].iloc[:, [-1]]\n",
    "\n",
    "infrastructure_dfs['rail_length'] = infrastructure_dfs['rail_length'].iloc[:, [-2]]\n",
    "infrastructure_dfs['rail_length'].columns = ['len_rail']\n",
    "\n",
    "infrastructure_dfs['length_oil'] = infrastructure_dfs['length_oil'].iloc[:, [-1]]\n",
    "infrastructure_dfs['length_oil'].columns = ['len_oil']\n",
    "\n",
    "# Coose dataframes to compile\n",
    "chosen_dfs = [infrastructure_dfs['motorway'], infrastructure_dfs['length_road'], infrastructure_dfs['rail_length'], \n",
    "                        infrastructure_dfs['length_oil']]\n",
    "\n",
    "# Compile everything into 1 dataframe\n",
    "infrastructure_all = pd.concat(chosen_dfs, axis=1, ignore_index=False)\n",
    "infrastructure_all = infrastructure_all.drop(\"EU27\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each column\n",
    "infrastructure_all.hist(bins=15, figsize=(8, 5))  \n",
    "plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "plt.show()\n",
    "\n",
    "# Investigating log-transformations\n",
    "infrastructure_all_log = infrastructure_all.apply(lambda x: np.log(x) if np.issubdtype(x.dtype, np.number) else x)\n",
    "infrastructure_all_log.hist(bins=15, figsize=(8, 5))  \n",
    "plt.tight_layout()  # Ensure proper spacing between subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means of Transport\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "file_path = '../data/StatisticalPocketbook/pb2023_section26.xlsx'\n",
    "\n",
    "# Specify the sheet names\n",
    "sheet_names = ['stock_cars', 'stock_busses']\n",
    "\n",
    "# Read the specified sheets into a dictionary of DataFrames\n",
    "means_transp_dfs = pd.read_excel(file_path, sheet_name=sheet_names, header=4, index_col=1)\n",
    "\n",
    "# Remove rows containing only NaN-s\n",
    "for name, df in means_transp_dfs.items():\n",
    "    df.dropna(how='all', inplace=True)\n",
    "    print(f\"DataFrame for sheet {name}:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of registered cars\n",
    "means_transp_dfs['stock_cars'] = means_transp_dfs['stock_cars'].iloc[:, [-1]]\n",
    "means_transp_dfs['stock_cars'].columns = ['stock_cars']\n",
    "\n",
    "# Number of registered busses\n",
    "means_transp_dfs['stock_busses'] = means_transp_dfs['stock_busses'].iloc[:, [-1]]\n",
    "means_transp_dfs['stock_busses'].columns = ['stock_busses']\n",
    "\n",
    "# Compile to 1 dataframe:\n",
    "chosen_dfs = [means_transp_dfs['stock_cars'], means_transp_dfs['stock_busses']]\n",
    "means_transp_all = pd.concat(chosen_dfs, axis=1, ignore_index=False)\n",
    "means_transp_all = means_transp_all.drop(\"EU-27\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each column\n",
    "means_transp_all.hist(bins=15, figsize=(8, 3))  \n",
    "plt.tight_layout()  \n",
    "plt.show()\n",
    "\n",
    "# Look at log-distribution\n",
    "np.log(means_transp_all).hist(bins=15, figsize=(8, 3))  \n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all dfs into files\n",
    "general_all.to_csv('../data/StatisticalPocketbook/general_all.csv')\n",
    "transport_all.to_csv('../data/StatisticalPocketbook/transport_all.csv')\n",
    "infrastructure_all.to_csv('../data/StatisticalPocketbook/generainfrastructure_alll_all.csv')\n",
    "means_transp_all.to_csv('../data/StatisticalPocketbook/means_transp_all.csv')\n",
    "\n",
    "# Modal split\n",
    "modal_split.to_csv('../data/StatisticalPocketbook/modal_split.csv')\n",
    "modal_split_proz.to_csv('../data/StatisticalPocketbook/modal_split_proz.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
